{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim Glove 300D - 201a_gg300_sent.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download Gensim Model\n",
    "\n",
    "Download a pre-trained word embedding model compatible with Gensim. For example, the Google News Word2Vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget -c \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "# unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Download Dataset\n",
    "\n",
    "Download a sentiment analysis dataset. For example, the airline sentiment dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget -c \"'https://archive.org/download/misc-dataset/airline-tweets.csv'\"\n",
    "#tar -xvzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load Gensim Model\n",
    "Load the pre-trained model using Gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\zl\\venv\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\zl\\venv\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\zl\\venv\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\zl\\venv\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\zl\\venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe model\n",
    "glove_path = r\"C:/ZL/model/glove.6B.300d.txt\"\n",
    "glove_embeddings = load_glove_embeddings(glove_path)\n",
    "print(\"GloVe model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Load Airline Sentiment Dataset\n",
    "Load and explore the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
      "0  570306133677760513           neutral                        1.0000   \n",
      "1  570301130888122368          positive                        0.3486   \n",
      "2  570301083672813571           neutral                        0.6837   \n",
      "3  570301031407624196          negative                        1.0000   \n",
      "4  570300817074462722          negative                        1.0000   \n",
      "\n",
      "  negativereason  negativereason_confidence         airline  \\\n",
      "0            NaN                        NaN  Virgin America   \n",
      "1            NaN                     0.0000  Virgin America   \n",
      "2            NaN                        NaN  Virgin America   \n",
      "3     Bad Flight                     0.7033  Virgin America   \n",
      "4     Can't Tell                     1.0000  Virgin America   \n",
      "\n",
      "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
      "0                    NaN     cairdin                 NaN              0   \n",
      "1                    NaN    jnardino                 NaN              0   \n",
      "2                    NaN  yvonnalynn                 NaN              0   \n",
      "3                    NaN    jnardino                 NaN              0   \n",
      "4                    NaN    jnardino                 NaN              0   \n",
      "\n",
      "                                                text tweet_coord  \\\n",
      "0                @VirginAmerica What @dhepburn said.         NaN   \n",
      "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
      "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
      "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
      "\n",
      "               tweet_created tweet_location               user_timezone  \n",
      "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
      "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
      "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
      "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
      "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n",
      "airline_sentiment\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = r\"C:\\ZL\\dataset\\_airsent\\airline-tweets.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Explore data\n",
    "print(data.head())\n",
    "print(data['airline_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Preprocess\n",
    "Preprocess the text and convert sentiment labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "data['tokens'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Convert sentiment to numerical labels\n",
    "sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "data['label'] = data['airline_sentiment'].map(sentiment_map)\n",
    "print(\"Preprocessing completed!\")\n",
    "# 1m 9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Vectorize\n",
    "Convert text into word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_vector_glove(tokens, embeddings_index, vector_size=300):\n",
    "    vectors = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)  # Average of word vectors\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Apply vectorization\n",
    "data['vector'] = data['tokens'].apply(lambda x: text_to_vector_glove(x, glove_embeddings))\n",
    "X = np.vstack(data['vector'].values)\n",
    "y = data['label'].values\n",
    "# 0.2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Train\n",
    "Split the dataset into training and test sets, and train a Logistic Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Predict\n",
    "Predict sentiment on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed!\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Prediction completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Evaluate\n",
    "Evaluate the model's performance using common metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.92      0.87      1889\n",
      "           0       0.59      0.44      0.50       580\n",
      "           1       0.75      0.62      0.68       459\n",
      "\n",
      "    accuracy                           0.78      2928\n",
      "   macro avg       0.72      0.66      0.68      2928\n",
      "weighted avg       0.76      0.78      0.76      2928\n",
      "\n",
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe-based model achieved an **accuracy of 78%**, slightly lower than the Word2Vec model (79%). \n",
    "\n",
    "Breakdown of the results and observations:\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Observations from GloVe Results**\n",
    "1. **Class-wise Performance**:\n",
    "   - **Negative Sentiment (-1)**: \n",
    "     - **Precision (82%)** and **Recall (92%)** remain strong, similar to Word2Vec.\n",
    "     - The **F1-Score (87%)** reflects balanced performance for this dominant class.\n",
    "   - **Neutral Sentiment (0)**: \n",
    "     - Performance for this class remains challenging:\n",
    "       - **Precision (59%)** and **Recall (44%)** are both slightly lower than the Word2Vec results.\n",
    "       - **F1-Score (50%)** indicates room for improvement in identifying neutral sentiments.\n",
    "   - **Positive Sentiment (1)**:\n",
    "       - Comparable performance to Word2Vec with a **Precision (75%)** and **Recall (62%)**.\n",
    "       - **F1-Score (68%)** is slightly lower than Word2Vec (70%).\n",
    "\n",
    "2. **Macro Average**:\n",
    "   - **F1-Score (68%)** is lower than Word2Vec's 70%, showing a slight decrease in balanced performance across all classes.\n",
    "\n",
    "3. **Weighted Average**:\n",
    "   - **F1-Score (76%)** is close to Word2Vec, reflecting the model's strength in predicting the majority class (negative sentiment).\n",
    "\n",
    "4. **Class Imbalance**:\n",
    "   - GloVe struggles similarly with the underrepresented classes (neutral and positive), likely due to class imbalance in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison: GloVe vs. Word2Vec**\n",
    "| Metric                | Word2Vec | GloVe |\n",
    "|-----------------------|----------|-------|\n",
    "| Accuracy              | 79%      | 78%   |\n",
    "| Negative F1-Score (-1)| 87%      | 87%   |\n",
    "| Neutral F1-Score (0)  | 53%      | 50%   |\n",
    "| Positive F1-Score (1) | 70%      | 68%   |\n",
    "| Macro F1-Score        | 70%      | 68%   |\n",
    "| Weighted F1-Score     | 78%      | 76%   |\n",
    "\n",
    "---\n",
    "\n",
    "### **Suggestions for Further Improvement**\n",
    "1. **Fine-tune GloVe Embeddings**:\n",
    "   - Use domain-specific data (e.g., airline reviews) to fine-tune the GloVe embeddings.\n",
    "\n",
    "2. **Hybrid Approach**:\n",
    "   - Combine GloVe and Word2Vec embeddings for richer word representations.\n",
    "   - Use embedding concatenation or weighted averaging.\n",
    "\n",
    "3. **Advanced Models**:\n",
    "   - Experiment with FastText, which may better handle out-of-vocabulary words and rare words.\n",
    "   - Use contextual embeddings like **BERT** or **RoBERTa** for improved performance.\n",
    "\n",
    "4. **Handling Class Imbalance**:\n",
    "   - Apply **oversampling** for minority classes or **class-weighting** in the Logistic Regression loss function.\n",
    "   - Use data augmentation techniques to create synthetic samples for neutral and positive sentiments.\n",
    "\n",
    "5. **Explore Deep Learning Models**:\n",
    "   - Train LSTMs, CNNs, or hybrid models with pre-trained GloVe embeddings for potentially better results.\n",
    "\n",
    "While GloVe offers strong performance, Word2Vec slightly outperforms it in this case, especially for the neutral and positive classes. Adopting some of the suggestions could help further refine the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
